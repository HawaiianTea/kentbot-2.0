# ─────────────────────────────────────────────────────────────────────────────
# .env.example — Template for your secret settings
#
# Copy this file to ".env" and fill in your real values.
# NEVER commit the real .env file to git — it contains secret tokens!
# ─────────────────────────────────────────────────────────────────────────────

# ── Discord ──────────────────────────────────────────────────────────────────
# Your bot's secret token from https://discord.com/developers/applications
# This is how your bot proves its identity to Discord.
DISCORD_TOKEN=your_discord_token_here

# Your bot's application ID from the Discord developer portal.
# Needed to register slash commands with Discord.
CLIENT_ID=your_client_id_here

# (Optional) A specific server/guild ID to register commands in for testing.
# If left blank, commands are registered globally (takes ~1 hour to appear everywhere).
# If set, commands appear in that one server instantly — great for testing!
GUILD_ID=your_guild_id_here

# ── OpenAI (for DALL-E recipe images only) ───────────────────────────────────
# Your OpenAI API key from https://platform.openai.com/api-keys
# Only needed for generating recipe images — all text is handled locally by Ollama.
OPENAI_API_KEY=your_openai_api_key_here

# ── Service Ports (optional, these are the defaults) ─────────────────────────
# The port the music service listens on. Bot will call this service for YouTube lookups.
MUSIC_SERVICE_PORT=3001

# The port the AI service listens on. Bot will call this for recipes, DJ intros, and TTS.
AI_SERVICE_PORT=3002

# ── Ollama (local LLM server) ─────────────────────────────────────────────────
# The URL of your local Ollama server. Ollama must be installed and running.
# Install: curl -fsSL https://ollama.com/install.sh | sh
# Pull model: ollama pull llama3.2:3b
OLLAMA_URL=http://localhost:11434

# The Ollama model to use for text generation (recipes, DJ intros).
OLLAMA_MODEL=llama3.2:3b

# ── TTS (Text-to-Speech) ─────────────────────────────────────────────────────
# Which TTS provider to use: 'local' or 'elevenlabs'
#   'local'       — Coqui XTTS v2 running on your machine (slow on weak hardware)
#   'elevenlabs'  — ElevenLabs cloud API (fast, requires API key below)
TTS_PROVIDER=local

# Path to the .wav file that XTTS v2 clones the voice from (only used when TTS_PROVIDER=local).
# The file should be a clear, noise-free WAV recording, at least 6 seconds long.
TTS_VOICE_SAMPLE=voice-samples/kent.wav

# ElevenLabs API key — get one at https://elevenlabs.io/ (only needed when TTS_PROVIDER=elevenlabs)
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here

# ElevenLabs voice ID — find IDs in your ElevenLabs voice library or the pre-made voice list.
# Example preset voices: JBFqnCBsd6RMkjVDRZzb (George), ErXwobaYiN019PkySvjV (Antoni)
# You can also clone a voice on ElevenLabs and paste its ID here.
ELEVENLABS_VOICE_ID=your_voice_id_here

# ElevenLabs model — controls quality vs. speed trade-off (only needed when TTS_PROVIDER=elevenlabs)
#   eleven_flash_v2_5      — fastest, lowest latency, good for DJ intros (default)
#   eleven_multilingual_v2 — highest quality, slower
ELEVENLABS_MODEL=eleven_flash_v2_5
